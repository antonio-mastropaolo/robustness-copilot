{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metrics-Extraction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziStkqDYNG2R"
      },
      "outputs": [],
      "source": [
        "!pip install javalang\n",
        "! pip install -q torch==1.4.0 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "! pip install -q transformers==3.5.0 fast-trees\n",
        "! git clone -q https://github.com/microsoft/CodeXGLUE.git\n",
        "import re\n",
        "import javalang\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Copilot-Robustness/NonFullContext-Result.csv',index_col='index')"
      ],
      "metadata": {
        "id": "1i-A6ucPOLY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein(seq1, seq2):\n",
        "    \n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "                \n",
        "    return (matrix[size_x - 1, size_y - 1])\n",
        "\n",
        "\n",
        "def levenshtein_normalized(seq1, seq2):\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "    return matrix[size_x - 1, size_y - 1]/max(size_x, size_y)\n",
        "\n",
        "target = list(df['body'])\n",
        "original = list(df['generatedResultOriginal'])\n",
        "perturbedEvaluator = list(df['generatedResultEvaluator'])\n",
        "perturbatedPivoting = list(df['generatedResultPivoting'])\n",
        "perturbatedPegasus = list(df['generatedResultPegasus'])\n",
        "\n",
        "resultOriginalMethods = list(df['mvnTestResultOriginal'])\n",
        "resultEvaluator = list(df['mvnTestResultEvaluator'])\n",
        "resultPivoting = list(df['mvnTestResultPivoting'])\n",
        "resultPegasus = list(df['mvnTestResultPegasus'])"
      ],
      "metadata": {
        "id": "TaZHW3FUNWm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "originalJavaDoc = list(df['javaDocFirstSentence'])\n",
        "perturbedJavaDocEvaluator = list(df['perturbed_eval_1'])\n",
        "perturbedJavaDocPivoting = list(df['pivotingPerturbed'])\n",
        "perturbedJavaDocPegasus = list(df['pegasusPerturbed'])\n",
        "\n",
        "\n",
        "#Lev distance computation for code\n",
        "\n",
        "levDistanceTargetOriginal = []\n",
        "levDistanceTargetEvaluator = []\n",
        "levDistanceTargetPivoting = []\n",
        "levDistanceTargetPegasus = []\n",
        "levDistanceTargetOriginalNorm = []\n",
        "levDistanceTargetEvaluatorNorm = []\n",
        "levDistanceTargetPivotingNorm = []\n",
        "levDistanceTargetPegasusNorm = []\n",
        "\n",
        "levDistanceOriginalEvaluator = []\n",
        "levDistanceOriginalPivoting = []\n",
        "levDistanceOriginalPegasus = []\n",
        "levDistanceOriginalEvaluatorNorm = []\n",
        "levDistanceOriginalPivotingNorm = []\n",
        "levDistanceOriginalPegasusNorm = []\n",
        "\n",
        "for (targetMethod, originalMethod, perturbedEvaluatorMethod, perturbatedPivotingMethod, perturbatedPegasusMethod, resultOriginalMethod, resultEvaluatorMethod, resultPivotingMethod, resultPegasusMethod) in tqdm(zip(target, original, perturbedEvaluator, perturbatedPivoting, perturbatedPegasus, resultOriginalMethods, resultEvaluator, resultPivoting, resultPegasus)):\n",
        "\n",
        "  originalBodyTokens = []\n",
        "  targetBodyTokens = []\n",
        "\n",
        "  if originalMethod == 'Empty Method' or resultOriginalMethod == 'Not Valid' or resultOriginalMethod == 'Syntax Error':\n",
        "      \n",
        "      # levDistanceOriginalEvaluator.append('None')\n",
        "      # levDistanceOriginalEvaluatorNorm.append('None')\n",
        "\n",
        "      # levDistanceOriginalPivoting.append('None')\n",
        "      # levDistanceOriginalPivotingNorm.append('None')\n",
        "      \n",
        "      # levDistanceOriginalPegasus.append('None')\n",
        "      # levDistanceOriginalPegasusNorm.append('None')\n",
        "\n",
        "      levDistanceTargetOriginal.append('None')\n",
        "      levDistanceTargetOriginalNorm.append('None')\n",
        "     \n",
        "  \n",
        "  else:\n",
        "    originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "    targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "    lev = levenshtein(originalBodyTokens, targetBodyTokens)\n",
        "    levDistanceTargetOriginal.append(lev)\n",
        "\n",
        "    levNorm = levenshtein_normalized(originalBodyTokens, targetBodyTokens)\n",
        "    levDistanceTargetOriginalNorm.append(levNorm)\n",
        "\n",
        "  ##################################################################################################\n",
        "  \n",
        "  if perturbedEvaluatorMethod == 'Empty Method' or resultEvaluatorMethod == 'Not Valid' or resultEvaluatorMethod == 'Syntax Error':\n",
        "    \n",
        "    levDistanceOriginalEvaluator.append('None')\n",
        "    levDistanceOriginalEvaluatorNorm.append('None')\n",
        "\n",
        "    levDistanceTargetEvaluator.append('None')\n",
        "    levDistanceTargetEvaluatorNorm.append('None')\n",
        "  \n",
        "  else:\n",
        "    try:\n",
        "      originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "      evaluatorBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbedEvaluatorMethod))]\n",
        "      targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "      lev = levenshtein(originalBodyTokens, evaluatorBodyTokens)\n",
        "      levDistanceOriginalEvaluator.append(lev)\n",
        "\n",
        "      levNorm = levenshtein_normalized(originalBodyTokens, evaluatorBodyTokens)\n",
        "      levDistanceOriginalEvaluatorNorm.append(levNorm)\n",
        "\n",
        "      lev = levenshtein(targetBodyTokens, evaluatorBodyTokens)\n",
        "      levDistanceTargetEvaluator.append(lev)\n",
        "\n",
        "      levNorm = levenshtein_normalized(targetBodyTokens, evaluatorBodyTokens)\n",
        "      levDistanceTargetEvaluatorNorm.append(levNorm)\n",
        "\n",
        "    except Exception:\n",
        "      \n",
        "      levDistanceOriginalEvaluator.append('None')\n",
        "      levDistanceOriginalEvaluatorNorm.append('None')\n",
        "\n",
        "      levDistanceTargetEvaluator.append('None')\n",
        "      levDistanceTargetEvaluatorNorm.append('None')\n",
        "\n",
        "  ##################################################################################################\n",
        "\n",
        "  if perturbatedPivotingMethod == 'Empty Method' or resultPivotingMethod == 'Not Valid' or perturbatedPivotingMethod == 'Syntax Error':\n",
        "      \n",
        "      levDistanceOriginalPivoting.append('None')\n",
        "      levDistanceOriginalPivotingNorm.append('None')\n",
        "\n",
        "      levDistanceTargetPivoting.append('None')\n",
        "      levDistanceTargetPivotingNorm.append('None')\n",
        "\n",
        "  else:          \n",
        "      try:\n",
        "        originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "        pivotingBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbatedPivotingMethod))]\n",
        "        targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "        lev = levenshtein(originalBodyTokens, pivotingBodyTokens)\n",
        "        levDistanceOriginalPivoting.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(originalBodyTokens, pivotingBodyTokens)\n",
        "        levDistanceOriginalPivotingNorm.append(levNorm)\n",
        "\n",
        "        lev = levenshtein(targetBodyTokens, pivotingBodyTokens)\n",
        "        levDistanceTargetPivoting.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(targetBodyTokens, pivotingBodyTokens)\n",
        "        levDistanceTargetPivotingNorm.append(levNorm)\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "\n",
        "        levDistanceOriginalPivoting.append('None')\n",
        "        levDistanceOriginalPivotingNorm.append('None')\n",
        "\n",
        "        levDistanceTargetPivoting.append('None')\n",
        "        levDistanceTargetPivotingNorm.append('None')\n",
        "\n",
        "  ##################################################################################################\n",
        "  if perturbatedPegasusMethod == 'Empty Method' or resultPegasusMethod == 'Not Valid' or perturbatedPegasusMethod == 'Syntax Error':\n",
        "      \n",
        "      levDistanceOriginalPegasus.append('None')\n",
        "      levDistanceOriginalPegasusNorm.append('None')\n",
        "\n",
        "      levDistanceTargetPegasus.append('None')\n",
        "      levDistanceTargetPegasusNorm.append('None')\n",
        "  \n",
        "  else:\n",
        "      try:\n",
        "        originalBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(originalMethod))]\n",
        "        pegasusBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(perturbatedPegasusMethod))]\n",
        "        targetBodyTokens = [token.value for token in list(javalang.tokenizer.tokenize(targetMethod))]\n",
        "\n",
        "        lev = levenshtein(originalBodyTokens, pegasusBodyTokens)\n",
        "        levDistanceOriginalPegasus.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(originalBodyTokens, pegasusBodyTokens)\n",
        "        levDistanceOriginalPegasusNorm.append(levNorm)\n",
        "\n",
        "        lev = levenshtein(targetBodyTokens, pegasusBodyTokens)\n",
        "        levDistanceTargetPegasus.append(lev)\n",
        "\n",
        "        levNorm = levenshtein_normalized(targetBodyTokens, pegasusBodyTokens)\n",
        "        levDistanceTargetPegasusNorm.append(levNorm)\n",
        "\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "        \n",
        "        levDistanceOriginalPegasus.append('None')\n",
        "        levDistanceOriginalPegasusNorm.append('None')\n",
        "        \n",
        "        levDistanceTargetPegasus.append('None')\n",
        "        levDistanceTargetPegasusNorm.append('None')\n",
        "  ##################################################################################################\n",
        "\n",
        "\n",
        "len(levDistanceOriginalEvaluator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDAEOD-LNXk2",
        "outputId": "1b943546-386c-43f5-abb8-48309a2b1327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "892it [04:46,  3.11it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "892"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lev distance computation for javadoc\n",
        "\n",
        "levDistanceOriginalJavaDocEvaluator = []\n",
        "levDistanceOriginalJavaDocPivoting = []\n",
        "levDistanceOriginalJavaDocPegasus = []\n",
        "\n",
        "levDistanceOriginalJavaDocEvaluatorNorm = []\n",
        "levDistanceOriginalJavaDocPivotingNorm = []\n",
        "levDistanceOriginalJavaDocPegasusNorm = []\n",
        "\n",
        "for (javaDocOriginal, javaDocEvaluator, javaDocPivoting, javaDocPegasus) in tqdm(zip(originalJavaDoc, perturbedJavaDocEvaluator, perturbedJavaDocPivoting, perturbedJavaDocPegasus)):\n",
        "\n",
        "    levDistanceOriginalJavaDocEvaluator.append(levenshtein(javaDocOriginal.split(), javaDocEvaluator.split()))\n",
        "    levDistanceOriginalJavaDocEvaluatorNorm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocEvaluator.split()))\n",
        "\n",
        "    levDistanceOriginalJavaDocPivoting.append(levenshtein(javaDocOriginal.split(), javaDocPivoting.split()))\n",
        "    levDistanceOriginalJavaDocPivotingNorm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocPivoting.split()))\n",
        "    \n",
        "    levDistanceOriginalJavaDocPegasus.append(levenshtein(javaDocOriginal.split(), javaDocPegasus.split()))\n",
        "    levDistanceOriginalJavaDocPegasusNorm.append(levenshtein_normalized(javaDocOriginal.split(), javaDocPegasus.split()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-GpEY6ONXvA",
        "outputId": "dd9345b4-c11e-4e32-d5ed-dc583933ce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "892it [00:02, 368.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "codeBleuAgainstOriginal = []\n",
        "codeBleuAgainstEvaluator = []\n",
        "codeBleuAgainstPivoting = []\n",
        "codeBleuAgainstPegasus = []\n",
        "\n",
        "\n",
        "for (targetMethod, originalMethod, perturbedEvaluatorMethod, perturbatedPivotingMethod, perturbatedPegasusMethod, resultOriginalMethod, resultEvaluatorMethod, resultPivotingMethod, resultPegasusMethod) in tqdm(zip(target, original, perturbedEvaluator, perturbatedPivoting, perturbatedPegasus, resultOriginalMethods, resultEvaluator, resultPivoting, resultPegasus)):\n",
        "\n",
        "  if originalMethod == 'Empty Method' or resultOriginalMethod == 'Not Valid' or resultOriginalMethod == 'Syntax Error':\n",
        "      codeBleuAgainstOriginal.append('None')\n",
        "  else:\n",
        "      \n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          originalBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(originalMethod))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          \n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(originalBodyTokens)\n",
        "          \n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "        \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "        \n",
        "          codeBleuAgainstOriginal.append('{}'.format(codeBleuScore))\n",
        "      \n",
        "      except Exception:\n",
        "        codeBleuAgainstOriginal.append('None')\n",
        "        \n",
        "\n",
        "  if perturbedEvaluatorMethod == 'Empty Method' or resultEvaluatorMethod == 'Not Valid' or resultEvaluatorMethod == 'Syntax Error':\n",
        "      codeBleuAgainstEvaluator.append('None')\n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          evaluatorBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbedEvaluatorMethod))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(evaluatorBodyTokens)\n",
        "          \n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "      \n",
        "          infoScore = res[0]\n",
        "\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "\n",
        "          codeBleuAgainstEvaluator.append('{}'.format(codeBleuScore))\n",
        "\n",
        "      except Exception:\n",
        "        codeBleuAgainstEvaluator.append('None')\n",
        "        \n",
        "\n",
        "  if perturbatedPivotingMethod == 'Empty Method' or resultPivotingMethod == 'Not Valid' or resultPivotingMethod == 'Syntax Error':\n",
        "      codeBleuAgainstPivoting.append('None')\n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          pivotingBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbatedPivotingMethod))])\n",
        "\n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(pivotingBodyTokens)\n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "      \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "      \n",
        "          codeBleuAgainstPivoting.append('{}'.format(codeBleuScore))\n",
        "\n",
        "\n",
        "      except Exception:\n",
        "          codeBleuAgainstPivoting.append('None')\n",
        "      \n",
        "  if perturbatedPegasusMethod == 'Empty Method' or resultPegasusMethod == 'Not Valid' or resultPegasusMethod == 'Syntax Error':\n",
        "      codeBleuAgainstPegasus.append('None')\n",
        "  \n",
        "  else:\n",
        "      groundTruthBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(targetMethod))])\n",
        "      \n",
        "      try:\n",
        "          pegasusBodyTokens = ' '.join([token.value for token in list(javalang.tokenizer.tokenize(perturbatedPegasusMethod))])\n",
        "      \n",
        "          with open('reference.txt','w') as f:\n",
        "            f.write(groundTruthBodyTokens)\n",
        "          with open('prediction.txt','w') as f:\n",
        "            f.write(pegasusBodyTokens)\n",
        "          res = !cd /content/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/ && python calc_code_bleu.py --refs /content/reference.txt --hyp /content/prediction.txt --lang java --params 0.25,0.25,0.25,0.25\n",
        "          \n",
        "          infoScore = res[0]\n",
        "          codeBleuScore = res[1].split(':')[1].split(',')[0]\n",
        "          codeBleuAgainstPegasus.append('{}'.format(codeBleuScore))\n",
        "      \n",
        "      except Exception:\n",
        "          codeBleuAgainstPegasus.append('None')\n",
        "\n",
        "df['CodeBleuOriginal'] = codeBleuAgainstOriginal\n",
        "df['CodeBleuEvaluator'] = codeBleuAgainstEvaluator\n",
        "df['CodeBleuPivoting'] = codeBleuAgainstPivoting\n",
        "df['CodeBleuPegasus'] = codeBleuAgainstPegasus\n",
        "\n",
        "df['levenshteinTarget-Original-Code'] =  levDistanceTargetOriginal\n",
        "df['levenshteinTarget-Original-Code-Normalized'] =  levDistanceTargetOriginalNorm\n",
        "\n",
        "df['levenshteinTarget-Evaluator-Code'] =  levDistanceTargetEvaluator\n",
        "df['levenshteinTarget-Evaluator-Code-Normalized'] =  levDistanceTargetEvaluatorNorm\n",
        "\n",
        "df['levenshteinTarget-Pivoting-Code'] =  levDistanceTargetPivoting\n",
        "df['levenshteinTarget-Pivoting-Code-Normalized'] =  levDistanceTargetPivotingNorm\n",
        "\n",
        "df['levenshteinTarget-Pegasus-Code'] =  levDistanceTargetPegasus\n",
        "df['levenshteinTarget-Pegasus-Code-Normalized'] =  levDistanceTargetPegasusNorm\n",
        "\n",
        "######################################################################\n",
        "\n",
        "\n",
        "df['levenshteinOriginal-Evaluator-Code'] = levDistanceOriginalEvaluator\n",
        "df['levenshteinOriginal-Evaluator-Code-Normalized'] = levDistanceOriginalEvaluatorNorm\n",
        "\n",
        "df['levenshteinOriginal-Pivoting-Code'] = levDistanceOriginalPivoting\n",
        "df['levenshteinOriginal-Pivoting-Code-Normalized'] = levDistanceOriginalPivotingNorm\n",
        "\n",
        "\n",
        "df['levenshteinOriginal-Pegasus-Code'] = levDistanceOriginalPegasus\n",
        "df['levenshteinOriginal-Pegasus-Code-Normalized'] = levDistanceOriginalPegasusNorm\n",
        "\n",
        "######################################################################\n",
        "\n",
        "df['levenshteinOriginal-Evaluator-JavaDoc'] = levDistanceOriginalJavaDocEvaluator\n",
        "df['levenshteinOriginal-Evaluator-JavaDoc-Normalized'] = levDistanceOriginalJavaDocEvaluatorNorm\n",
        "\n",
        "df['levenshteinOriginal-Pivoting-JavaDoc'] = levDistanceOriginalJavaDocPivoting\n",
        "df['levenshteinOriginal-Pivoting-JavaDoc-Normalized'] = levDistanceOriginalJavaDocPivotingNorm\n",
        "\n",
        "df['levenshteinOriginal-Pegasus-JavaDoc'] = levDistanceOriginalJavaDocPegasus\n",
        "df['levenshteinOriginal-Pegasus-JavaDoc-Normalized'] = levDistanceOriginalJavaDocPegasusNorm\n",
        "\n",
        "# df.to_csv('Non-FullContext-Result1.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoBIo2ZzNrGJ",
        "outputId": "0d4f1fbf-dcfb-4e29-ba46-35a22fffe465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "892it [12:04,  1.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "qEFrbe2rPgI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('NonFullContext-With-Stats.csv')"
      ],
      "metadata": {
        "id": "DEghqcoaR_tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qd3uMOK_SVnp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}